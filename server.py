from flask import Flask, request, jsonify, send_from_directory
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import requests
from bs4 import BeautifulSoup
import re
import time
from flask_cors import CORS
import os

app = Flask(__name__, static_folder="static", static_url_path="")
CORS(app) 

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
print("–ó–∞–≥—Ä—É–∂–∞–µ–º NER –º–æ–¥–µ–ª—å...")
try:
    model = AutoModelForTokenClassification.from_pretrained("./ner_model/checkpoint-125")
    tokenizer = AutoTokenizer.from_pretrained("./ner_model/checkpoint-125")
    ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")
    print("‚úÖ NER –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    ner_pipeline = None

def extract_possible_titles(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
        response = requests.get(url, headers=headers, timeout=10)

        if response.status_code != 200:
            print(f"[SKIP] {url}: Status code {response.status_code}")
            return []

        soup = BeautifulSoup(response.content, "lxml")
        candidates = []

        # –ò–∑–≤–ª–µ–∫–∞–µ–º h1 –∑–∞–≥–æ–ª–æ–≤–∫–∏
        for tag in soup.find_all(['h1']):
            text = tag.get_text(strip=True)
            if text:
                candidates.append(text)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª–∞—Å—Å–∞–º–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ "name", "title"
        for tag in soup.find_all(['p', 'div', 'span']):
            cls = tag.get("class")
            if cls and any(any(substr in c.lower() for substr in ["name", "title"]) for c in (cls if isinstance(cls, list) else [cls])):
                text = tag.get_text(strip=True)
                if text:
                    candidates.append(text)

        return candidates

    except requests.exceptions.RequestException as e:
        print(f"[ERROR] {url}: {e}")
        return []

def process_with_ner(texts):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ NER –º–æ–¥–µ–ª—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
    if not ner_pipeline:
        return []
    
    results = []
    
    for text in texts:
        if not text or len(text.strip()) < 2:
            continue
            
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –º–æ–¥–µ–ª–∏
            entities = ner_pipeline(text)
            
            # –ò—â–µ–º —Å—É—â–Ω–æ—Å—Ç–∏ —Å –º–µ—Ç–∫–æ–π PRODUCT
            for entity in entities:
                if entity.get('entity_group') == 'PRODUCT' or entity.get('entity') == 'PRODUCT':
                    confidence = entity.get('score', 0)
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏ –æ–∫—Ä—É–≥–ª—è–µ–º
                    prob_percent = f"{int(confidence * 100)}%"
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Å—å –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—É—é —Å—É—â–Ω–æ—Å—Ç—å
                    results.append({
                        "text": text,
                        "prob": prob_percent
                    })
                    break  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º, —Ç–∞–∫ –∫–∞–∫ —É–∂–µ –Ω–∞—à–ª–∏ PRODUCT –≤ —ç—Ç–æ–º —Ç–µ–∫—Å—Ç–µ
                    
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ '{text}': {e}")
            continue
    
    return results

@app.route('/api/analyze', methods=['POST'])
def analyze_url():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ–±–µ–ª–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()
        
        if not data or 'url' not in data:
            return jsonify({"error": "URL –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω"}), 400
        
        url = data['url']
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è URL
        if not url.startswith(('http://', 'https://')):
            return jsonify({"error": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL"}), 400
        
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º URL: {url}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        titles = extract_possible_titles(url)
        
        if not titles:
            return jsonify({"results": [], "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏—è —Å –¥–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"})
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(titles)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        unique_titles = []
        seen = set()
        for title in titles:
            if title not in seen:
                unique_titles.append(title)
                seen.add(title)
        
        print(f"–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(unique_titles)} –Ω–∞–∑–≤–∞–Ω–∏–π")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ NER –º–æ–¥–µ–ª—å
        results = process_with_ner(unique_titles)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (—É–±–∏—Ä–∞–µ–º % –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏)
        results.sort(key=lambda x: int(x['prob'].replace('%', '')), reverse=True)
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(results)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –º–µ–±–µ–ª–∏")
        
        return jsonify({
            "results": results,
            "total_titles_found": len(unique_titles),
            "products_identified": len(results)
        })
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return jsonify({"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
    model_status = "loaded" if ner_pipeline else "not_loaded"
    return jsonify({
        "status": "ok",
        "model_status": model_status
    })
    
@app.route('/', defaults={'path': ''})
@app.route('/<path:path>')
def serve_react(path):
    file_path = os.path.join(app.static_folder, path)
    if path != "" and os.path.exists(file_path):
        return send_from_directory(app.static_folder, path)
    else:
        return send_from_directory(app.static_folder, 'index.html')    

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º Flask —Å–µ—Ä–≤–µ—Ä...")
    print("üìù –î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:")
    print("  POST /analyze - –∞–Ω–∞–ª–∏–∑ URL –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ–±–µ–ª–∏")
    print("  GET /health - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞")
    
    app.run(debug=True, host='0.0.0.0', port=5000)